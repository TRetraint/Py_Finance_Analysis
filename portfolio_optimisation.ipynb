{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the project\n",
    "PATH_STOCK = os.getcwd() + \"/stocks/\"\n",
    "\n",
    "# Default start and end dates\n",
    "START = \"2017-02-01\"\n",
    "END = \"2022-01-30\"\n",
    "START_DATE = pd.to_datetime(START)\n",
    "END_DATE = pd.to_datetime(END)\n",
    "\n",
    "# Approximate 10 year bond rate, long term vision\n",
    "RISK_FREE_RATE = 0.0125 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = read_stock(x, PATH_STOCK)\n",
    "        \n",
    "        # NEW Check if your dataframe has duplicate indexes\n",
    "        # if not df.index.is_unique:\n",
    "        #     # Delete duplicates \n",
    "        #     df = df.loc[~df.index.duplicated(), :]\n",
    "        \n",
    "        mask = (df.index >= sdate) & (df.index <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markowitz Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harry Markowitz proved that you could make what is called an efficient portfolio. That is a portfolio that optimizes return while also minimizing risk. We don't benefit from analyzing individual securities at the same rate as if we instead considered a portfolio of stocks.\n",
    "\n",
    "We do this by creating portfolios with stocks that are not correlated. We want to calculate expected returns by analyzing the returns of each stock multiplied by its weight. \n",
    "\n",
    "$w_1r_1 + w_2r_2 = r_p$\n",
    "\n",
    "The standard deviation of the portfolio is found this way. Sum multiple calculations starting by finding the product of the first securities weight squared times its standard deviation squared. The middle is 2 times the correlation coefficient between the stocks. And, finally add those to the weight squared times the standard deviation squared for the second security.\n",
    "\n",
    "$(w_1\\sigma_1 + w_2\\sigma_2)^2 = w_1^2\\sigma_1^2 + 2w_1\\sigma_1w_2\\sigma_2\\rho_1 + w_2^2\\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_list = ['PLUG', 'AMRC', 'ARWR', 'ZYXI', 'ENPH', 'APPS', 'TTGT', 'ROKU',\n",
    "             'FRPT', 'DAR', 'MSEX', 'NEE', 'ATLC', 'KNSL', 'VRS', 'LPX',\n",
    "             'IIPR', 'PW', 'OAS', 'LEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df = merge_df_by_column_name('Close',  START, END, *port_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Price of Portfolio's Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out prices for each stock since beginning of 2017\n",
    "fig = px.line(mult_df, x=mult_df.index, y=mult_df.columns)\n",
    "fig.update_xaxes(title=\"Date\", rangeslider_visible=True)\n",
    "fig.update_yaxes(title=\"Price\")\n",
    "fig.update_layout(height=1200, width=1800, \n",
    "                  showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_cum_df = merge_df_by_column_name('cum_return',  START, END, *port_list)\n",
    "mult_cum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out cumulative returns for each stock since beginning of 2017\n",
    "fig = px.line(mult_cum_df, x=mult_cum_df.index, y=mult_cum_df.columns)\n",
    "fig.update_xaxes(title=\"Date\", rangeslider_visible=True)\n",
    "fig.update_yaxes(title=\"Price\")\n",
    "fig.update_layout(height=1200, width=1800, \n",
    "                  showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = np.log(mult_df / mult_df.shift(1))\n",
    "mean_ret = returns.mean() * 252  # 252 average trading days per year\n",
    "mean_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Weights Equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.random(len(port_list))\n",
    "weights /= np.sum(weights)\n",
    "print('Weights :', weights)\n",
    "print('Total Weight :', np.sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Returns & Risks of 100000 Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = [] # Returns list\n",
    "p_vol = [] # Volatility list\n",
    "p_SR = [] # Sharpe Ratio list\n",
    "p_wt = [] # Stock weights list\n",
    "\n",
    "num_combinations = 100000\n",
    "\n",
    "for x in range(num_combinations):\n",
    "    # Generate random weights\n",
    "    p_weights = np.random.random(len(port_list))\n",
    "    p_weights /= np.sum(p_weights)\n",
    "    \n",
    "    # Add return using those weights to list\n",
    "    ret_1 = np.sum(p_weights * returns.mean()) * 252\n",
    "    p_ret.append(ret_1)\n",
    "    \n",
    "    # Add volatility or standard deviation to list\n",
    "    vol_1 = np.sqrt(np.dot(p_weights.T, np.dot(returns.cov() * 252, p_weights)))\n",
    "    p_vol.append(vol_1)\n",
    "    \n",
    "    # Get Sharpe ratio\n",
    "    SR_1 = (ret_1 - RISK_FREE_RATE) / vol_1\n",
    "    p_SR.append(SR_1)\n",
    "    \n",
    "    # Store the weights for each portfolio\n",
    "    p_wt.append(p_weights)\n",
    "    \n",
    "# Convert to Numpy arrays\n",
    "p_ret = np.array(p_ret)\n",
    "p_vol = np.array(p_vol)\n",
    "p_SR = np.array(p_SR)\n",
    "p_wt = np.array(p_wt)\n",
    "\n",
    "p_ret, p_vol, p_SR, p_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People want to maximize returns while avoiding as much risk as possible. William Sharpe created the Sharpe Ratio to find the portfolio that provides the best return for the lowest amount of risk. \n",
    "\n",
    "*Sharpe Ratio* = $\\frac{r_i - r_f}{\\sigma_i}$\n",
    "\n",
    "$r_f = $ Risk Free Rate\n",
    "\n",
    "$r_i = $ Rate of Return of the stock\n",
    "\n",
    "$\\sigma_i = $ Standard Deviation of the Stock\n",
    "\n",
    "As return increases so does the Sharpe Ratio, but as Standard Deviation increase the Sharpe Ration decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the index of the largest Sharpe Ratio\n",
    "SR_idx = np.argmax(p_SR)\n",
    "\n",
    "# Find the ideal portfolio weighting at that index\n",
    "i = 0\n",
    "while i < len(port_list):\n",
    "    print(\"Stock : %s : %2.2f\" % (port_list[i], (p_wt[SR_idx][i] * 100)))\n",
    "    i += 1\n",
    "    \n",
    "# Find volatility of that portfolio\n",
    "print(\"\\nVolatility :\", p_vol[SR_idx])\n",
    "      \n",
    "# Find return of that portfolio\n",
    "print(\"Return :\", p_ret[SR_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_shares(one_price, force_one, wts, prices):\n",
    "    # Gets number of stocks to analyze\n",
    "    num_stocks = len(wts)\n",
    "    \n",
    "    # Holds the number of shares for each\n",
    "    shares = []\n",
    "    \n",
    "    # Holds Cost of shares for each\n",
    "    cost_shares = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_stocks:\n",
    "        # Get max amount to spend on stock \n",
    "        max_price = one_price * wts[i]\n",
    "        \n",
    "        # Gets number of shares to buy and adds them to list\n",
    "        num_shares = int(max_price / prices[i])\n",
    "        \n",
    "        # If the user wants to force buying one share do it\n",
    "        if(force_one & (num_shares == 0)):\n",
    "            num_shares = 1\n",
    "        \n",
    "        shares.append(num_shares)\n",
    "        \n",
    "        # Gets cost of those shares and appends to list\n",
    "        cost = num_shares * prices[i]\n",
    "        cost_shares.append(cost)\n",
    "        i += 1\n",
    "        \n",
    "    return shares, cost_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Portfolio Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_weighting(share_cost):\n",
    "    \n",
    "    # Holds weights for stocks\n",
    "    stock_wts = []\n",
    "    # All values summed\n",
    "    tot_val = sum(share_cost)\n",
    "    print(\"Total Investment :\", tot_val)\n",
    "    \n",
    "    for x in share_cost:\n",
    "        stock_wts.append(x / tot_val)\n",
    "    return stock_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns the Value of Portfolio by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_val_by_date(date, shares, tickers):\n",
    "    port_prices = merge_df_by_column_name('Close',  date, \n",
    "                                  date, *port_list)\n",
    "    # Convert from dataframe to Python list\n",
    "    port_prices = port_prices.values.tolist()\n",
    "    # Trick that converts a list of lists into a single list\n",
    "    port_prices = sum(port_prices, [])\n",
    "    return port_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(port_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_wts = [7, 8, 15, 14, 3, 3, 17, 6, 11, 14,\n",
    "            1, 9, 2, 3, 11, 3, 2, 4, 12, 13]\n",
    "\n",
    "# Get all stock prices on the starting date\n",
    "port_df_start = merge_df_by_column_name('Close',  '2022-01-07', \n",
    "                                  '2022-01-07', *port_list)\n",
    "# Convert from dataframe to Python list\n",
    "port_prices = port_df_start.values.tolist()\n",
    "\n",
    "# Trick that converts a list of lists into a single list\n",
    "port_prices = sum(port_prices, [])\n",
    "\n",
    "tot_shares, share_cost = get_port_shares(110, True, port_wts, port_prices)\n",
    "print(\"Shares :\", tot_shares)\n",
    "print(\"Share Cost :\", share_cost)\n",
    "\n",
    "# Get list of weights for stocks\n",
    "stock_wts = get_port_weighting(share_cost)\n",
    "print(\"Stock Weights :\", stock_wts)\n",
    "\n",
    "# Get value at end of year\n",
    "get_port_val_by_date(END, tot_shares, port_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc044dbeba82771aaeccdb8770a998b04de1e1141a3b5ed0d819352aa1a1f7bf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
